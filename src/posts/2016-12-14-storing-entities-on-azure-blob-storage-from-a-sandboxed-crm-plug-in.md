---
id: 1003
title: Storing entities on Azure blob storage from a sandboxed CRM plug-in
date: 2016-12-14T09:53:46+01:00
updated: 2021-07-16T22:45:25+02:00
author: Michaël Hompus
excerpt: >
  This post will be about a new sample of using “Sandboxable”.

  We will walk through the steps to create a Microsoft Dynamics CRM plug-in that on deletion of any record,
  stores the deleted data as a file on Azure blob storage.
layout: ../layouts/BlogPost.astro
permalink: /2016/12/14/storing-entities-on-azure-blob-storage-from-a-sandboxed-crm-plug-in/
image: /wp-content/uploads/2016/12/post-1003-thumbnail.png
categories:
  - Azure
  - C#
  - Dynamics CRM
tags:
  - Azure
  - Blob
  - CRM
  - NuGet
  - Plugin
  - Sandbox
  - SDK
---

This post will be about a new sample of using "[Sandboxable](/2016/07/13/introducing-sandboxable-use-your-favorite-azure-nuget-packages-in-a-sandbox-environment)".
<time datetime="2016-11-25">Earlier</time> I wrote an article about [sending messages on an Azure queue](/2016/11/25/sending-a-message-to-an-azure-queue-from-a-sandboxed-crm-plug-in).

In this article, I will walk through the steps to create a Microsoft Dynamics CRM plug-in that on deletion of any record,
stores the deleted data as a file on Azure blob storage.

<!--more-->

> [!NOTE]
> When using Azure blobs to store data, you should enable [Azure Storage Service Encryption for Data at Rest](https://docs.microsoft.com/en-us/azure/storage/common/storage-service-encryption).

As usual, you will find the links to the [complete source code](#sample-code) at the end of this post.

## Setting up the project

For this sample, the steps for [setting up the project](/2016/11/25/sending-a-message-to-an-azure-queue-from-a-sandboxed-crm-plug-in#setting-up-the-project) are the same as the steps described in the previous post.
So, I will not list them here again.

## Writing the plug-in

I have based the plug-in code on the MSDN article "[Write a plug-in](<https://learn.microsoft.com/previous-versions/dynamicscrm-2016/developers-guide/gg328263(v=crm.8)>)".

### Getting the deleted entity

To get the details about the deleted record we need to get them from the [`PreEntityImage` collection](<https://learn.microsoft.com/previous-versions/dynamicscrm-2016/developers-guide/gg326980(v=crm.8)>).
The registration of a `Pre-Image` will be described later in this post.

```csharp
Entity entity = context.PreEntityImages["Target"];
```

### Getting the connection details

To connect to Azure blob storage, you need 2 details.

1. The storage account name.
2. One of the storage account access keys.

For this sample, I will use a JSON string stored in the secure storage property of the plug-in step.

To deserialize these settings we use `JsonConvert` with a nested `PluginSettings` class.

```csharp
PluginSettings pluginSettings =
      JsonConvert.DeserializeObject<PluginSettings>(this.secureString);
```

### Initializing the Cloud Blob Client

The [`CloudBlobClient` class](https://learn.microsoft.com/dotnet/api/microsoft.azure.storage.blob.cloudblobclient?view=azure-dotnet-legacy) offers an easy way to manage and use all Azure blob storage related resources.

To initialize this class, we need to provide the URL and the [StorageCredentials](https://learn.microsoft.com/dotnet/api/microsoft.azure.storage.auth.storagecredentials?view=azure-dotnet-legacy).

```csharp
StorageCredentials storageCredentials =
      new StorageCredentials(pluginSettings.AccountName, pluginSettings.Key);

Uri baseUri =
      new Uri($"https://{pluginSettings.AccountName}.blob.core.windows.net");

CloudBlobClient blobClient =
      new CloudBlobClient(baseUri, storageCredentials);
```

### Creating a root container

First, make sure there is a container to store all the contents generated by this plug-in.

With the blob client, we can create a reference to the [CloudBlobContainer](https://learn.microsoft.com/dotnet/api/microsoft.azure.storage.blob.cloudblobcontainer?view=azure-dotnet-legacy) with the name that is stored in the constant named `FolderName`.

To make sure the container exists, we call the [`CreateIfNotExists` method](https://learn.microsoft.com/dotnet/api/microsoft.azure.storage.blob.cloudblobcontainer.createifnotexistsasync?view=azure-dotnet-legacy) which ensures us if there is not a container present yet, it will be created at that moment.

```csharp
CloudBlobContainer container = blobClient.GetContainerReference(FolderName);

container.CreateIfNotExists();
```

### Creating an entity directory

Now we want to create a directory inside the container to store entity specific records.

```csharp
CloudBlobDirectory entityDirectory =
      container.GetDirectoryReference(entity.LogicalName);
```

> [!NOTE]
> Directories differ from containers because they do not exist on disk.
> That is why we do not need to check if the directory already exists.
> If you are interested in more details, I recommend the article [Modeling a Directory Structure on Azure Blob Storage](https://johnatten.com/2013/05/24/modeling-a-directory-structure-on-azure-blob-storage/) by John Atten.

### Adding a blob to the directory

Just like the container and the directory before, we also need to create a reference for the blob.

On the blob directory ask for a reference to the [CloudBlockBlob](https://learn.microsoft.com/dotnet/api/microsoft.azure.storage.blob.cloudblockblob?view=azure-dotnet-legacy) using the [`GetBlockBlobReference` method](https://learn.microsoft.com/dotnet/api/microsoft.azure.storage.blob.cloudblobcontainer.getblockblobreference?view=azure-dotnet-legacy).

```csharp
string fileName = entity.Id.ToString("N") + ".json";

CloudBlockBlob blob = entityDirectory.GetBlockBlobReference(fileName);
```

We will not create the blob immediately because we want to add some details about the content we are about to store.
This can be done by setting the `Properties` and `Metadata` properties of the blob.

One of the [BlobProperties](https://learn.microsoft.com/dotnet/api/microsoft.azure.storage.blob.blobproperties?view=azure-dotnet-legacy)
we want to set is the [`ContentType` property](https://learn.microsoft.com/dotnet/api/microsoft.azure.storage.blob.blobproperties.contenttype?view=azure-dotnet-legacy).
This will allow other systems to recognize the file correctly as a JSON file.

```csharp
blob.Properties.ContentType = "application/json";
```

However, the `BlobProperties` only contains a fixed set of properties.

By using the [`Metadata` property](https://learn.microsoft.com/dotnet/api/microsoft.azure.storage.blob.cloudblob.metadata?view=azure-dotnet-legacy)
on the blob allows us to store custom metadata with the blob.

```csharp
blob.Metadata["userid"] = context.UserId.ToString("B").ToLowerInvariant();
blob.Metadata["userfullname"] = fullName;
blob.Metadata["deletiondate"] = context.OperationCreatedOn.ToString("O");
```

Now it is time to write some file contents to the blob.
We create blob data, using the context of the current plug-in execution.
For demonstration purposes we serialize the JSON with the [Formatting](https://www.newtonsoft.com/json/help/html/T_Newtonsoft_Json_Formatting.htm) option set to `Indented`.

Because the blob content is plain text, we can use the [UploadText method](https://learn.microsoft.com/dotnet/api/microsoft.azure.storage.blob.cloudblockblob.uploadtext?view=azure-dotnet-legacy).

```csharp
var blobData = new
  {
    context.UserId,
    FullName = fullName,
    context.MessageName,
    entity.LogicalName,
    entity.Id,
    entity.Attributes
  };

blob.UploadText(JsonConvert.SerializeObject(blobData, Formatting.Indented));
```

Now build the project so we can proceed.

## Register the plug-in assembly

Now the freshly baked assembly needs to be registered on the server.  
The steps to do this are outside the scope for this post, but more information can be found in the
[walkthrough: Register a plug-in using the plug-in registration tool](<https://learn.microsoft.com/previous-versions/dynamicscrm-2016/developers-guide/gg309580(v=crm.8)>).

## Register the plug-in step for an event

To test the plug-in, we’ll register it asynchronously on the deletion event of every entity.

> [!WARNING]
> Dependencies on external resources should never be part of a synchronous pipeline.

In the `Secure Configuration` property, we set the value with the JSON object containing the connection information:

```json
{
  "AccountName": "loremipsum",
  "Key": "DDWLOREM...IPSUMr0A=="
}
```

<small>(Obviously, these values do not represent real data)</small>

![Register the plug-in step for the deletion event of any entity](/wp-content/uploads/2016/12/register-step-delete-all-entities.png)

Because we are working with the deletion event, we need to register a `Pre-Image` to capture the values of all attributes before the actual deletion took place.

We set the value of the `Name` and the `Entity Alias` properties to `Target`

![Register a new image for the plug-in step for the deletion event of any entity](/wp-content/uploads/2016/12/register-new-image-delete-all-entities.png)

## Testing the plug-in

We delete a contact in CRM. In my case the contact is called _Sample User_.

After a couple of seconds, we see the following container and directories appear on the storage account:

![The "samplecrmfolder" container with multiple directories for different entities](/wp-content/uploads/2016/12/sample-crm-folder.png)

<small>Screenshot from [Azure Management Studio by Cerebrata](https://cerebrata.com/features/azure-storage)</small>

Opening the file in the `contact` directory, shows us some familiar content:

```json
{
  "UserId": "d617a1a0-359a-e411-9407-00155d0ae259",
  "FullName": "Lorem Ipsum",
  "MessageName": "Delete",
  "LogicalName": "contact",
  "Id": "6e843a34-91b1-e611-80e4-00155d0a0b40",
  "Attributes": [
    {
      "Key": "firstname",
      "Value": "Sample"
    },
    {
      "Key": "lastname",
      "Value": "User"
    },
    {
      "Key": "fullname",
      "Value": "Sample User"
    },
    ...
  ]
}
```

If we look at the HTTP response header when retrieving the file,
we see that the content type and metadata properties are present:

```http {2,5-7}
HTTP/1.1 200 OK
Content-Type: application/json
Server: Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
x-ms-version: 2015-12-11
x-ms-meta-userid: {d617a1a0-359a-e411-9407-00155d0ae259}
x-ms-meta-userfullname: Lorem Ipsum
x-ms-meta-deletiondate: 2016-12-08T14:23:25.5635361Z
x-ms-blob-type: BlockBlob
```

## Concluding

By utilizing the Sandboxable Azure SDK, we only needed a few lines of code to store deleted CRM records in Azure blob storage, making a remote archive a piece of cake.

> [!TIP]
> When using blob storage for archiving you might want to look at
> [Blob Storage Accounts with Cool storage tier](https://learn.microsoft.com/azure/storage/blobs/access-tiers-overview?tabs=azure-portal#cold-tier)
> which might save you same money.

## Sample code

The complete source code is available as a [sample project](https://github.com/Winvision/Sandboxable-Samples/tree/master/src/CrmBlob).

Expect more samples in the [Sandboxable-Samples repository on GitHub](https://github.com/Winvision/Sandboxable-Samples) in the future.
